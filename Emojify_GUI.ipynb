{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a685bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 12:48:58.401830: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a56400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 12:48:59.650496: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-08 12:48:59.733931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2022-07-08 12:48:59.733958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-08 12:48:59.736304: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-08 12:48:59.736334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-08 12:48:59.753320: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-08 12:48:59.753497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-08 12:48:59.753843: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-07-08 12:48:59.754299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-08 12:48:59.754396: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-08 12:48:59.754778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-07-08 12:48:59.755409: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-08 12:48:59.756140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2022-07-08 12:48:59.756434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-07-08 12:48:59.756463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-08 12:49:00.066515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-08 12:49:00.066550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-07-08 12:49:00.066557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-07-08 12:49:00.067114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2652 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "face_model = Sequential()\n",
    "face_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "face_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Flatten())\n",
    "face_model.add(Dense(1024, activation='relu'))\n",
    "face_model.add(Dropout(0.5))\n",
    "face_model.add(Dense(7, activation='softmax'))\n",
    "face_model.load_weights('recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49a775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df98dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_dict = {0: \"   Angry   \", 1: \"Disgusted\", 2: \"  Fearful  \", 3: \"   Happy   \", 4: \"  Neutral  \", 5: \"    Sad    \", 6: \"Surprised\"}\n",
    "emojis_dict = {0:\"emojis/angry.png\", 1:\"emojis/disgusted.png\", 2:\"emojis/fearful.png\", 3:\"emojis/happy.png\", 4:\"emojis/neutral.png\", 5:\"emojis/sad.png\", 6:\"emojis/surprised.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c56df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global last_frame1                         \n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "show_text=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffc11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Capture_Image():\n",
    "    global cap1\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    if not cap1.isOpened():\n",
    "        print(\"cant open the camera1\")\n",
    "    flag1, frame1 = cap1.read()\n",
    "    frame1 = cv2.resize(frame1,(600,500))\n",
    "    bound_box = cv2.CascadeClassifier('/home/pkm/Desktop/ML Project/haarcascades_cuda/haarcascade_frontalface_default.xml')#it will detect the face in the video and bound it with a rectangular b\n",
    "    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    n_faces = bound_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in n_faces:\n",
    "        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_frame = gray_frame[y:y + h, x:x + w]\n",
    "        crop_img = np.expand_dims(np.expand_dims(cv2.resize(roi_frame, (48, 48)), -1), 0)\n",
    "        prediction = face_model.predict(crop_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        cv2.putText(frame1, facial_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        show_text[0]=maxindex\n",
    "\n",
    "    if flag1 is None:\n",
    "        print (\"Error!\")\n",
    "\n",
    "    elif flag1:\n",
    "        global last_frame1\n",
    "        last_frame1 = frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB) #to store the image   \n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        lmain.after(10, Capture_Image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit()\n",
    "    \n",
    "def Get_Emoji():\n",
    "    frame2=cv2.imread(emojis_dict[show_text[0]])\n",
    "    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)\n",
    "    img2=Image.fromarray(frame2)\n",
    "    imgtk2=ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.imgtk2=imgtk2\n",
    "    lmain3.configure(text=facial_dict[show_text[0]],font=('arial',45,'bold'))\n",
    "    lmain2.configure(image=imgtk2)\n",
    "    lmain2.after(10, Get_Emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90634c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"140046848275968Get_Emoji\"\n",
      "    while executing\n",
      "\"140046848275968Get_Emoji\"\n",
      "    (\"after\" script)\n",
      "[ WARN:0@123.529] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pkm/anaconda3/lib/python3.9/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/home/pkm/anaconda3/lib/python3.9/tkinter/__init__.py\", line 814, in callit\n",
      "    func(*args)\n",
      "  File \"/tmp/ipykernel_31598/3896258343.py\", line 7, in Capture_Image\n",
      "    frame1 = cv2.resize(frame1,(600,500))\n",
      "cv2.error: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant open the camera1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    root=tk.Tk()  \n",
    "    heading = Label(root,bg='black')\n",
    "    heading.pack()\n",
    "    heading2=Label(root,text=\"Emojify\",pady=20, font=('arial',45,'bold'),bg='black',fg='#CDCDCD')#to label the output                                \n",
    "    heading2.pack()\n",
    "    lmain = tk.Label(master=root,padx=50,bd=10)\n",
    "    lmain2 = tk.Label(master=root,bd=10)\n",
    "    lmain3=tk.Label(master=root,bd=10,fg=\"#CDCDCD\",bg='black')\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain.place(x=50,y=250)\n",
    "    lmain3.pack()\n",
    "    lmain3.place(x=960,y=250)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    lmain2.place(x=900,y=350)\n",
    "    root.title(\"Emojify\")           \n",
    "    root.geometry(\"1400x900+100+10\")\n",
    "    root['bg']='black'\n",
    "    exitbutton = Button(root, text='Quit',fg=\"red\",command=root.destroy,font=('arial',25,'bold')).pack(side = BOTTOM)\n",
    "    Capture_Image()\n",
    "    Get_Emoji()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6dd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d966fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
